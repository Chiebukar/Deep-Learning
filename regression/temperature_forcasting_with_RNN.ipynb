{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temperature_forcasting_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOUFxd+wc5vScz3zxM+QOq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiebukar/Deep-Learning/blob/main/regression/temperature_forcasting_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLIsQ2DMhIEq"
      },
      "source": [
        "## Temperature Forcasting with Jena climate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qByXOnVng9By"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBi-8N-Ii8Fr"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7vU3Ff6rLdi"
      },
      "source": [
        "!kaggle datasets download -d kusuri/jena-climate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2yAqRsExURM"
      },
      "source": [
        "!ls -d $PWD/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRyA60oDy24R"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_sx1mHky4An"
      },
      "source": [
        "!ls -d $PWD/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oQbUkaJy9s0"
      },
      "source": [
        "file_dir = '/content/jena_climate_2009_2016.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2rDBB7LzDn-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UisvqRKHzRfe"
      },
      "source": [
        "jena_df = pd.read_csv(file_dir)\n",
        "jena_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJRKEMCyzsZy"
      },
      "source": [
        "jena_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKIrYgapzzJj"
      },
      "source": [
        "jena_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKlk8WA20D7d"
      },
      "source": [
        "jena_arr = np.array(jena_df.iloc[:, 1:])\n",
        "jena_arr[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Dhl1bZ1kXS"
      },
      "source": [
        "# standardize data\n",
        "len_train = 200000\n",
        "mean = jena_arr[:len_train].mean(axis=0)\n",
        "std = jena_arr[:len_train].std(axis=0)\n",
        "jena_arr = (jena_arr-mean)/std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q0EcThP050k"
      },
      "source": [
        "# generator to yield batches of data from the recent past and future target  \n",
        "def generator(data, min_index, max_index , lookback= 1440, delay=144, step= 6, batch_size=18, shuffle=False):\n",
        "\n",
        "  \"\"\"\n",
        "  yield batches of data from the recent past and future target\n",
        "\n",
        "  data = original input data\n",
        "  min_index = minimum index of data to draw from\n",
        "  max_index  maximum index of sata to draw from\n",
        "  lookback= Number of timestamps back for input data per target\n",
        "  delay = Number of timestamp in the future for target per lookback\n",
        "  steps = period in timestamps to sample data\n",
        "  batch_size = number of samples per batch\n",
        "  shuffle = To shuffle the samples or not\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if max_index == None:\n",
        "    max_index = len(data) - delay - 1\n",
        "  i = min_index + lookback\n",
        "\n",
        "  while 1:\n",
        "    if shuffle:\n",
        "      rows = np.random.randint(min_index + lookback, max_index, size= batch_size)\n",
        "    else:\n",
        "      if i + batch_size >= max_index:\n",
        "        i = min_index + lookback\n",
        "      rows = np.arange(i, min(i + batch_size, max_index))\n",
        "      i += len(rows)\n",
        "    \n",
        "    samples = np.zeros((len(rows), lookback  //step, data.shape[-1]))\n",
        "    targets = np.zeros((len(rows),))\n",
        "\n",
        "    for j, row in  enumerate(rows):\n",
        "      indices = range(rows[j] - lookback, rows[j], step)\n",
        "      samples[j] = data[indices]\n",
        "      targets[j] = data[rows[j] + delay][1]\n",
        "    yield samples, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOFNM4B9AbgB"
      },
      "source": [
        "train_gen = generator(data= jena_arr,\n",
        "                      min_index= 0,\n",
        "                      max_index= 200000,\n",
        "                      shuffle= True)\n",
        "\n",
        "valid_gen = generator(data= jena_arr,\n",
        "                      min_index= 200001,\n",
        "                      max_index = 300000,\n",
        "                      shuffle = True)\n",
        "\n",
        "test_gen = generator(data = jena_arr,\n",
        "                     min_index = 300001,\n",
        "                     max_index = None,\n",
        "                     shuffle= True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybt8GjxmD_7k"
      },
      "source": [
        "# get validation and test steps\n",
        "lookback = 1440\n",
        "val_steps = (300000 - 200001 - lookback)\n",
        "test_steps = (len(jena_arr) - 300001 - lookback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRSqK8ZuDwZz"
      },
      "source": [
        "# establish baseline\n",
        "def evaluate_naive_method():\n",
        "  batch_maes = []\n",
        "  for step in range(val_steps):\n",
        "    samples, targets = next(valid_gen)\n",
        "    preds = samples[:, -1, 1]\n",
        "    mae = np.mean(np.abs(preds - targets))\n",
        "    batch_maes.append(mae)\n",
        "  return (np.mean(batch_maes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8_jjX8FwGq"
      },
      "source": [
        "# get baseline evaluation\n",
        "mae = evaluate_naive_method()\n",
        "celsius_mae = mae * std[1]\n",
        "celsius_mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28qYezWfH-FM"
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZiIhKmHkTa"
      },
      "source": [
        "# build model\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(32, dropout= 0.1, recurrent_dropout= 0.25,\n",
        "                 return_sequences=True,  input_shape = (None, jena_arr.shape[-1])))\n",
        "  model.add(LSTM(64, activation='tanh', dropout=0.5))\n",
        "  model.add(Dense(8, activation= 'relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(loss = 'mae', optimizer = 'rmsprop')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tmfr_5dbUUo"
      },
      "source": [
        "file_path= 'a_weights.best.hdf5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor= 'val_loss', save_best_only= True, verbose= 1, mode= 'min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca0ZTI2vca2P"
      },
      "source": [
        "model = build_model()\n",
        "history = model.fit(train_gen, steps_per_epoch = 500, epochs= 25, validation_data= valid_gen, \n",
        "                    validation_steps = 500, callbacks= checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqRFrjZ2dmoO"
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['mae', 'val_mae']].plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}